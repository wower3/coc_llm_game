from langchain_openai import ChatOpenAI
from langchain.messages import HumanMessage, AIMessage, SystemMessage
import os
from dotenv import load_dotenv 
load_dotenv(override=True)

MODELSCOPE_API_KEY = os.getenv("MODELSCOPE_API_KEY")
MODELSCOPE_URL = os.getenv("MODELSCOPE_URL")

# 1ï¸âƒ£ åˆå§‹åŒ–æ¨¡å‹ï¼ˆLangChain 1.0 æ¥å£ï¼‰
model = ChatOpenAI(
    model="deepseek-ai/DeepSeek-V3.1",
    api_key=MODELSCOPE_API_KEY,
    base_url=MODELSCOPE_URL,
    temperature=1.0
)

# 2ï¸âƒ£ åˆå§‹åŒ–ç³»ç»Ÿæç¤ºè¯ï¼ˆSystem Promptï¼‰
system_message = SystemMessage(
    content="ä½ å«å°æ™ºï¼Œæ˜¯ä¸€åä¹äºåŠ©äººçš„æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·åœ¨å¯¹è¯ä¸­ä¿æŒæ¸©å’Œã€æœ‰è€å¿ƒçš„è¯­æ°”ã€‚"
)

# 3ï¸âƒ£ åˆå§‹åŒ–æ¶ˆæ¯å†å²
messages = [system_message]

print("ğŸ”¹ è¾“å…¥ exit é€€å‡ºå¯¹è¯\n")

# 4ï¸âƒ£ ä¸»å¾ªç¯ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯ + æµå¼è¾“å‡ºï¼‰
while True:
    user_input = input("ğŸ‘¤ ä½ ï¼š")
    if user_input.lower() in {"exit", "quit"}:
        print("ğŸ§© å¯¹è¯ç»“æŸï¼Œå†è§ï¼")
        break

    # è¿½åŠ ç”¨æˆ·æ¶ˆæ¯
    messages.append(HumanMessage(content=user_input))

    # å®æ—¶è¾“å‡ºæ¨¡å‹ç”Ÿæˆå†…å®¹
    print("ğŸ¤– å°æ™ºï¼š", end="", flush=True)
    full_reply = ""

    # âœ… LangChain 1.0 æ ‡å‡†å†™æ³•ï¼šæµå¼è¾“å‡º
    for chunk in model.stream(messages):
        if chunk.content:
            print(chunk.content, end="", flush=True)
            full_reply += chunk.content

    print("\n" + "-" * 40)  # åˆ†éš”çº¿

    # è¿½åŠ  AI å›å¤æ¶ˆæ¯
    messages.append(AIMessage(content=full_reply))

    # ä¿æŒæ¶ˆæ¯é•¿åº¦ï¼ˆåªä¿ç•™æœ€è¿‘50è½®ï¼‰
    messages = messages[-50:]